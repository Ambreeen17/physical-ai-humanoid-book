{
  "metadata_schema": {
    "description": "RAG-ready chunks with full text content for Chapter 2: Kinematics and Dynamics",
    "version": "1.0",
    "generated_date": "2026-01-04",
    "source_chapter": "chapter-2",
    "total_chunks": 21,
    "overlap_strategy": "heading_boundary"
  },
  "chunks": [
    {
      "chunk_id": "ch2_theory_001",
      "chapter": 2,
      "section": "2.1",
      "subsection": null,
      "difficulty": "beginner",
      "content_type": "theory",
      "title": "Understanding Joint Space and Configuration Space",
      "keywords": ["joint_space", "configuration_space", "q_space", "C_space", "robot_configuration"],
      "learning_objectives": ["LO2.1"],
      "tokens": 285,
      "source_file": "content.md",
      "line_range": [13, 30],
      "content": "When you look at a robot arm, you see physical links moving through space. But to control that arm mathematically, you need a way to represent its configuration—not where it is in the world, but what shape it takes. This distinction leads us to two fundamental concepts: joint space and configuration space.\n\nImagine a simple 2-link planar arm, like a bent arm reaching forward. Each joint can rotate, and together the two joint angles determine the arm's entire shape. If joint 1 is at 30 degrees and joint 2 is at 45 degrees, that's a specific configuration. Change either angle and you get a different shape. The space of all possible pairs (q1, q2) is called joint space, denoted mathematically as the set of all joint angle combinations that the robot can physically achieve.\n\nNow consider the Unitree G1 humanoid robot. Each arm has 6 degrees of freedom: three at the shoulder, one at the elbow, and two at the wrist. That means the joint space is 6-dimensional—impossible to visualize directly, but mathematically straightforward. A configuration is simply a vector q = [q1, q2, q3, q4, q5, q6]^T where each element is the position of one joint.\n\nThe configuration space (or C-space) extends this idea to account for physical constraints. Joints have limits—your shoulder can't rotate 360 degrees without something breaking. The C-space is the subset of joint space where all these constraints are satisfied. For revolute joints with no constraints, C-space is a torus (like the surface of a donut, but n-dimensional). With limits, it becomes a bounded region shaped like a hyper-rectangle cut by additional constraints from self-collision avoidance."
    },
    {
      "chunk_id": "ch2_theory_002",
      "chapter": 2,
      "section": "2.1",
      "subsection": null,
      "difficulty": "beginner",
      "content_type": "theory",
      "title": "Workspace: Reachable vs Dexterous Workspace",
      "keywords": ["workspace", "reachable_workspace", "dexterous_workspace", "end_effector", "manipulation"],
      "learning_objectives": ["LO2.1"],
      "tokens": 198,
      "source_file": "content.md",
      "line_range": [27, 41],
      "content": "While joint space describes internal configurations, workspace describes what the robot can accomplish in the external world. Specifically, the workspace is the set of all positions the end-effector can reach. For the Unitree G1 arm with approximately 0.8 meters of reach, this forms roughly a sphere of radius 0.8 meters centered at the shoulder.\n\nThere are two important distinctions in workspace analysis. The reachable workspace includes all points the end-effector can reach, regardless of orientation—you just need to touch that point somehow. The dexterous workspace is smaller: points you can reach with any orientation you want. Near the boundary of the reachable workspace, you typically cannot achieve arbitrary orientations; the arm is fully extended and has 'used up' its degrees of freedom just to position the hand.\n\nThe relationship between C-space and workspace is not one-to-one. Multiple configurations in C-space can map to the same end-effector position (consider the elbow-up and elbow-down poses that reach the same point). This many-to-one mapping is why inverse kinematics has multiple solutions, while forward kinematics is always unique."
    },
    {
      "chunk_id": "ch2_theory_003",
      "chapter": 2,
      "section": "2.1",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Singularities and Robot Mobility",
      "keywords": ["singularities", "jacobian", "rank_deficiency", "mobility", "kinematic_singularities"],
      "learning_objectives": ["LO2.1"],
      "tokens": 215,
      "source_file": "content.md",
      "line_range": [35, 50],
      "content": "A singularity occurs when a robot temporarily loses the ability to move in certain directions, even though it still has the same number of joints. Mathematically, singularities happen when the Jacobian matrix—which maps joint velocities to end-effector velocities—drops in rank. At these configurations, the robot becomes temporarily 'stuck' in certain directions.\n\nConsider the 2-link arm when it becomes fully extended. With both links pointing in a straight line, you cannot produce motion perpendicular to that line without bending the arm first. The Jacobian becomes singular, and the joint velocities required to produce certain Cartesian velocities become infinitely large. This is why robots move slowly and carefully near singularities—the control system must avoid demanding impossible motions.\n\nThe Unitree G1 has several singularity configurations to avoid. The wrist singularity occurs when the two wrist joints align, losing one degree of freedom. Shoulder singularities happen when the arm is fully extended in certain directions. Good motion planning avoids these configurations or uses null-space projection to maneuver through them carefully.\n\nMany beginners assume singularities only occur at workspace boundaries. In reality, internal singularities can appear anywhere in the workspace. For a 6-DOF arm, the wrist singularity occurs when the wrist axes become parallel—an internal configuration that can trap unwary controllers."
    },
    {
      "chunk_id": "ch2_theory_004",
      "chapter": 2,
      "section": "2.2",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Homogeneous Transformations for Robot Kinematics",
      "keywords": ["homogeneous_transformations", "SE3", "rotation_matrix", "translation", "coordinate_frames"],
      "learning_objectives": ["LO2.2"],
      "tokens": 245,
      "source_file": "content.md",
      "line_range": [59, 78],
      "content": "Every link in a robot has its own coordinate frame. The base frame sits at the robot's base; the end-effector frame sits at the gripper. Between any two consecutive frames, we have a rotation and a translation. The elegant solution is to combine both into a single 4x4 matrix called a homogeneous transformation:\n\nT = [[R, t], [0, 1]] = [[r11, r12, r13, tx], [r21, r22, r23, ty], [r31, r32, r33, tz], [0, 0, 0, 1]]\n\nHere, R is a 3x3 rotation matrix and t is a 3x1 translation vector. The magic is that we can multiply these matrices to compose transformations. If frame B is at pose T_B relative to frame A, and frame C is at pose T_C relative to frame B, then frame C relative to frame A is simply T_A^C = T_A^B * T_B^C.\n\nChain of coordinate frames showing base (frame 0), intermediate frames (1, 2, 3), and end-effector frame (4). Arrows between frames show transformation matrices T01, T12, T23, T34. Final arrow shows T04 = T01 * T12 * T23 * T34."
    },
    {
      "chunk_id": "ch2_theory_005",
      "chapter": 2,
      "section": "2.2",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Denavit-Hartenberg Convention and Parameters",
      "keywords": ["DH_parameters", "denavit_hartenberg", "coordinate_frames", "transformation_matrix", "kinematic_model"],
      "learning_objectives": ["LO2.2"],
      "tokens": 275,
      "source_file": "content.md",
      "line_range": [71, 90],
      "content": "Assigning coordinate frames to every link would be messy without a standard approach. The Denavit-Hartenberg (DH) convention provides a systematic method using just four parameters per joint:\n\ntheta_i: The joint angle (rotation about z_{i-1})\nd_i: The link offset (translation along z_{i-1})\na_i: The link length (translation along x_i)\nalpha_i: The link twist (rotation about x_i)\n\nThe transformation from frame i-1 to frame i is:\n\nT_i = [[cos(theta), -sin(theta)*cos(alpha), sin(theta)*sin(alpha), a*cos(theta)], [sin(theta), cos(theta)*cos(alpha), -cos(theta)*sin(alpha), a*sin(theta)], [0, sin(alpha), cos(alpha), d], [0, 0, 0, 1]]\n\nFor a robot with n joints, we compute n such matrices and multiply them together. The end-effector pose relative to the base is T_ee = T_1 * T_2 * ... * T_n.\n\nThere are actually two DH conventions: 'standard' (where the frame is attached to the joint's input) and 'modified' (where the frame is attached to the joint's output). These differ in whether the frame transformation uses pre-multiplication or post-multiplication. Always document which convention you are using!"
    },
    {
      "chunk_id": "ch2_code_001",
      "chapter": 2,
      "section": "2.2",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "code",
      "title": "Forward Kinematics Implementation for Unitree G1",
      "keywords": ["forward_kinematics", "python", "numpy", "DH_transform", "Unitree_G1"],
      "learning_objectives": ["LO2.2"],
      "tokens": 485,
      "source_file": "content.md",
      "line_range": [92, 163],
      "content": "The Unitree G1 has 6-DOF arms. Here is how to implement forward kinematics in Python. We define a function to compute each DH transform and chain them together.\n\nimport numpy as np\n\ndef dh_transform(theta, d, a, alpha):\n    '''\n    Compute Denavit-Hartenberg transformation matrix.\n\n    Parameters:\n    - theta: joint angle (radians)\n    - d: link offset\n    - a: link length\n    - alpha: link twist (radians)\n\n    Returns: 4x4 homogeneous transformation matrix\n    '''\n    ct = np.cos(theta)\n    st = np.sin(theta)\n    ca = np.cos(alpha)\n    sa = np.sin(alpha)\n\n    T = np.array([\n        [ct, -st * ca, st * sa, a * ct],\n        [st, ct * ca, -ct * sa, a * st],\n        [0, sa, ca, d],\n        [0, 0, 0, 1]\n    ])\n    return T\n\ndef forward_kinematics_g1(joint_angles):\n    '''\n    Compute forward kinematics for Unitree G1 arm.\n\n    DH parameters for G1 arm (approximate):\n    Joint 1 (shoulder abduction/adduction): theta1, d=0, a=0, alpha=-pi/2\n    Joint 2 (shoulder flexion/extension): theta2, d=0, a=0.1, alpha=pi/2\n    Joint 3 (shoulder rotation): theta3, d=0, a=0.1, alpha=-pi/2\n    Joint 4 (elbow flexion): theta4, d=0, a=0.2, alpha=-pi/2\n    Joint 5 (wrist deviation): theta5, d=0, a=0, alpha=pi/2\n    Joint 6 (wrist rotation): theta6, d=0.1, a=0, alpha=0\n    '''\n    # Extract joint angles\n    q1, q2, q3, q4, q5, q6 = joint_angles\n\n    # Define DH parameters [theta, d, a, alpha]\n    dh_params = [\n        [q1, 0.0, 0.0, -np.pi/2],   # Joint 1: shoulder yaw\n        [q2, 0.0, 0.10, np.pi/2],   # Joint 2: shoulder pitch\n        [q3, 0.0, 0.10, -np.pi/2],  # Joint 3: shoulder roll\n        [q4, 0.0, 0.25, -np.pi/2],  # Joint 4: elbow\n        [q5, 0.0, 0.0, np.pi/2],    # Joint 5: wrist pitch\n        [q6, 0.12, 0.0, 0.0],       # Joint 6: wrist roll\n    ]\n\n    # Compute cumulative transformation\n    T_total = np.eye(4)\n    for params in dh_params:\n        T_i = dh_transform(*params)\n        T_total = T_total @ T_i  # Post-multiplication for standard DH\n\n    # Extract position and orientation\n    position = T_total[:3, 3]\n    rotation = T_total[:3, :3]\n\n    return T_total, position, rotation\n\n# Example: compute gripper position for a 'ready' pose\njoint_angles = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nT, pos, rot = forward_kinematics_g1(joint_angles)\n\nprint(f'End-effector position: {pos}')\nprint(f'End-effector orientation matrix:\\n{rot}')"
    },
    {
      "chunk_id": "ch2_theory_006",
      "chapter": 2,
      "section": "2.3",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "The Inverse Kinematics Problem",
      "keywords": ["inverse_kinematics", "IK", "SE3", "multiple_solutions", "reachability"],
      "learning_objectives": ["LO2.3"],
      "tokens": 225,
      "source_file": "content.md",
      "line_range": [179, 200],
      "content": "If forward kinematics asks 'where is my hand given my joints?', inverse kinematics asks the opposite: 'what joints do I need to reach a desired hand position?' This problem is fundamentally harder because multiple solutions may exist, some solutions may not exist at all, and finding solutions efficiently is non-trivial.\n\nFormally, given a desired end-effector pose T_des in SE(3), we want to find joint angles q such that FK(q) = T_des. Unlike forward kinematics, which has a unique solution for any configuration, inverse kinematics may have:\n\nNo solution: The desired pose is outside the workspace\nOne solution: A specific configuration reaches the pose\nMultiple solutions: Several configurations reach the same pose\nInfinite solutions: In redundant configurations (more DOF than needed)\n\nFor the Unitree G1's 6-DOF arm, there can be up to 16 solutions for a given reachable pose, though joint limits typically reduce this number."
    },
    {
      "chunk_id": "ch2_theory_007",
      "chapter": 2,
      "section": "2.3",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Analytical Solutions for Simple Robot Arms",
      "keywords": ["analytical_IK", "law_of_cosines", "geometric_IK", "closed_form_solution", "2DOF_arm"],
      "learning_objectives": ["LO2.3"],
      "tokens": 285,
      "source_file": "content.md",
      "line_range": [192, 248],
      "content": "For arms with 2 or 3 degrees of freedom, we can derive closed-form solutions using geometry. Consider a 2-DOF planar arm with link lengths L1 and L2. To reach a target (x, y), we form a triangle with sides L1, L2, and the distance r = sqrt(x^2 + y^2).\n\nThe law of cosines gives us the elbow angle:\n\ncos(theta_2) = (x^2 + y^2 - L_1^2 - L_2^2) / (2 * L_1 * L_2)\n\nThen we compute theta1 using atan2:\n\ntheta_1 = atan2(y, x) - atan2(L_2 * sin(theta_2), L_1 + L_2 * cos(theta_2))\n\nNotice that cos(theta_2) gives two possibilities: theta_2 and -theta_2. These correspond to the elbow-up and elbow-down configurations—the two major solution branches for 2-DOF arms.\n\nFor 3-DOF arms, a common approach is to first solve for the wrist position (decoupling position from orientation), then compute the wrist orientation separately. This works because the wrist joints often have intersecting axes at a common point."
    },
    {
      "chunk_id": "ch2_code_002",
      "chapter": 2,
      "section": "2.3",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "code",
      "title": "Analytical IK for 2-DOF Planar Arm",
      "keywords": ["analytical_IK", "elbow_up", "elbow_down", "law_of_cosines", "python"],
      "learning_objectives": ["LO2.3"],
      "tokens": 245,
      "source_file": "content.md",
      "line_range": [210, 246],
      "content": "def analytical_ik_2dof(x, y, L1, L2):\n    '''\n    Analytical inverse kinematics for 2-DOF planar arm.\n    Returns both solutions (elbow-up and elbow-down).\n    '''\n    r = np.sqrt(x**2 + y**2)\n\n    # Check reachability\n    if r > L1 + L2 or r < abs(L1 - L2):\n        return None, None  # Target unreachable\n\n    # Law of cosines for elbow angle\n    cos_theta2 = (r**2 - L1**2 - L2**2) / (2 * L1 * L2)\n    cos_theta2 = np.clip(cos_theta2, -1, 1)  # Numerical safety\n\n    # Two solutions: elbow-up and elbow-down\n    theta2_up = np.arccos(cos_theta2)\n    theta2_down = -np.arccos(cos_theta2)\n\n    # Compute theta1 for each case\n    phi = np.arctan2(y, x)\n    k1 = L1 + L2 * np.cos(theta2_up)\n    k2_up = L2 * np.sin(theta2_up)\n    theta1_up = phi - np.arctan2(k2_up, k1)\n\n    k1 = L1 + L2 * np.cos(theta2_down)\n    k2_down = L2 * np.sin(theta2_down)\n    theta1_down = phi - np.arctan2(k2_down, k1)\n\n    return [theta1_up, theta2_up], [theta1_down, theta2_down]\n\n# Example: reach position (1.0, 0.5) with L1=1.0, L2=0.8\nsolutions = analytical_ik_2dof(1.0, 0.5, 1.0, 0.8)\nprint(f'Solution 1 (elbow-up): {[np.degrees(a) for a in solutions[0]]} degrees')\nprint(f'Solution 2 (elbow-down): {[np.degrees(a) for a in solutions[1]]} degrees')"
    },
    {
      "chunk_id": "ch2_theory_008",
      "chapter": 2,
      "section": "2.3",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "theory",
      "title": "Numerical Methods: Jacobian and Damped Least Squares",
      "keywords": ["numerical_IK", "jacobian", "pseudo_inverse", "damped_least_squares", "iterative_methods"],
      "learning_objectives": ["LO2.3"],
      "tokens": 295,
      "source_file": "content.md",
      "line_range": [252, 283],
      "content": "For 6-DOF arms like the Unitree G1, analytical solutions are complex or impossible to derive. Instead, we use iterative numerical methods that start from an initial guess and converge toward a solution.\n\nThe core idea uses the Jacobian matrix, which relates joint velocities to end-effector velocities:\n\ndot{x} = J(q) dot{q}\n\nInverting this relationship gives:\n\ndot{q} = J^+ dot{x}\n\nwhere J^+ is the Moore-Penrose pseudo-inverse. For a small step, we can approximate the pose error as delta_x, then compute the joint correction:\n\nq_{k+1} = q_k + alpha * J^+ * e\n\nwhere e is the error between current and desired pose, and alpha is a step size.\n\nThe Jacobian pseudo-inverse J^+ = J^T (J J^T)^(-1) provides the minimum-norm solution—the smallest joint motion that achieves the desired Cartesian motion. This is important for smooth, efficient robot trajectories.\n\nThe basic Jacobian method fails near singularities because J J^T becomes nearly singular, causing enormous joint velocities. Damped Least Squares (DLS) fixes this by adding regularization:\n\nJ^+ = J^T (J J^T + lambda^2 I)^(-1)\n\nThe damping parameter lambda trades off between accuracy (small lambda) and stability near singularities (large lambda)."
    },
    {
      "chunk_id": "ch2_code_003",
      "chapter": 2,
      "section": "2.3",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "code",
      "title": "Numerical IK Implementation with Damped Least Squares",
      "keywords": ["numerical_IK", "DLS", "jacobian_computation", "convergence", "python"],
      "learning_objectives": ["LO2.3"],
      "tokens": 485,
      "source_file": "content.md",
      "line_range": [284, 353],
      "content": "def numerical_ik(target_pose, initial_q, dh_func, max_iterations=100, lambda_damping=0.1, tolerance=1e-4):\n    '''\n    Damped Least Squares inverse kinematics.\n\n    Parameters:\n    - target_pose: 4x4 desired end-effector transformation\n    - initial_q: starting joint configuration\n    - dh_func: function that computes FK given joint angles\n    - lambda_damping: regularization parameter\n    - tolerance: convergence threshold\n    '''\n    q = np.array(initial_q)\n\n    for iteration in range(max_iterations):\n        # Compute current pose and error\n        T_current, _, _ = dh_func(q)\n\n        # Pose error (using small angle approximation)\n        error = np.zeros(6)\n        error[:3] = target_pose[:3, 3] - T_current[:3, 3]  # Position error\n        rotation_error = target_pose[:3, :3] @ T_current[:3, :3].T\n        # Convert rotation matrix to axis-angle\n        rot_trace = np.trace(rotation_error)\n        if rot_trace > 2.9:  # Nearly identity\n            error[3:] = np.zeros(3)\n        else:\n            axis_angle = rotation_matrix_to_axis_angle(rotation_error)\n            error[3:] = axis_angle\n\n        # Check convergence\n        if np.linalg.norm(error) < tolerance:\n            print(f'Converged in {iteration} iterations')\n            return q\n\n        # Compute Jacobian (numerical approximation)\n        J = compute_jacobian(q, dh_func)\n\n        # Damped Least Squares\n        J_jtj = J @ J.T + lambda_damping**2 * np.eye(6)\n        delta_q = J.T @ np.linalg.solve(J_jtj, error)\n\n        # Update configuration\n        q = q + delta_q\n\n    print(f'Failed to converge after {max_iterations} iterations')\n    return q\n\ndef compute_jacobian(q, dh_func, delta=1e-6):\n    '''Numerical Jacobian computation.'''\n    n = len(q)\n    J = np.zeros((6, n))\n    T_base, _, _ = dh_func(q)\n\n    for i in range(n):\n        q_plus = q.copy()\n        q_plus[i] += delta\n        T_plus, _, _ = dh_func(q_plus)\n\n        # Linear velocity approximation\n        J[:3, i] = (T_plus[:3, 3] - T_base[:3, 3]) / delta\n\n        # Angular velocity approximation (simplified)\n        R_error = T_plus[:3, :3] @ T_base[:3, :3].T\n        rot_axis = rotation_matrix_to_axis_angle(R_error)\n        J[3:, i] = rot_axis / delta\n\n    return J"
    },
    {
      "chunk_id": "ch2_theory_009",
      "chapter": 2,
      "section": "2.4",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "theory",
      "title": "The Lagrangian Framework for Robot Dynamics",
      "keywords": ["lagrangian", "Euler_Lagrange", "kinetic_energy", "potential_energy", "generalized_coordinates"],
      "learning_objectives": ["LO2.4"],
      "tokens": 275,
      "source_file": "content.md",
      "line_range": [369, 400],
      "content": "Forward and inverse kinematics tell us where the robot is and where we want it to go. But how do we get there? That requires dynamics—understanding how forces and torques produce acceleration. The Lagrangian formulation provides an elegant, energy-based approach to deriving equations of motion.\n\nInstead of working with forces directly, the Lagrangian approach uses energies. The Lagrangian L is the difference between kinetic energy T and potential energy V:\n\nL = T - V\n\nThe Euler-Lagrange equation relates the Lagrangian to generalized forces (like joint torques):\n\nd/dt(partial L / partial dot{q}_i) - partial L / partial q_i = tau_i\n\nThis single equation generates complete equations of motion for any mechanical system—no free body diagrams, no constraint forces, no vector calculus spaghetti.\n\nFor a robot with n joints, the kinetic energy is:\n\nT = 1/2 * dot{q}^T * M(q) * dot{q}\n\nwhere M(q) is the symmetric positive-definite mass matrix (also called the inertia matrix). The mass matrix depends on configuration because each link's velocity depends on all joint angles—rotate the shoulder and the entire arm's center of mass shifts."
    },
    {
      "chunk_id": "ch2_theory_010",
      "chapter": 2,
      "section": "2.4",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "theory",
      "title": "Robot Dynamics Equation: M(q), C(q,qdot), g(q)",
      "keywords": ["robot_dynamics", "mass_matrix", "Coriolis_matrix", "gravity_vector", "equations_of_motion"],
      "learning_objectives": ["LO2.4"],
      "tokens": 315,
      "source_file": "content.md",
      "line_range": [403, 430],
      "content": "Gravitational potential energy is simply:\n\nV = sum_i m_i * g * h_i\n\nwhere h_i is the height of link i's center of mass above some reference (typically the floor). Unlike kinetic energy, potential energy depends only on configuration, not on velocity.\n\nApplying the Euler-Lagrange equation to the Lagrangian L = T - V yields the standard form of robot dynamics:\n\nM(q) * q_ddot + C(q, dot{q}) * dot{q} + g(q) = tau\n\nwhere:\nM(q) is the n x n mass matrix\nC(q, dot{q}) is the n x n Coriolis/centrifugal matrix\ng(q) is the n x 1 gravity vector\ntau is the n x 1 joint torque vector\n\nThe matrix C(q, dot{q}) deserves special attention. It contains two types of velocity-dependent terms: centrifugal terms (proportional to dot{q}_i^2) and Coriolis terms (proportional to dot{q}_i dot{q}_j). Together, they account for how motion in one joint affects forces in others.\n\nThe Coriolis matrix is not unique—multiple C matrices can satisfy the dynamics equation. The standard construction uses Christoffel symbols derived from the mass matrix: C_ij = sum_k Gamma_ijk * dot{q}_k where Gamma_ijk = (partial M_ij / partial q_k + partial M_ik / partial q_j - partial M_jk / partial q_i) / 2."
    },
    {
      "chunk_id": "ch2_math_001",
      "chapter": 2,
      "section": "2.4",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "math",
      "title": "Lagrangian Derivation for 2-Link Planar Arm",
      "keywords": ["Lagrangian_derivation", "2DOF_arm", "mass_matrix_derivation", "Christoffel_symbols", "symbolic_computation"],
      "learning_objectives": ["LO2.4"],
      "tokens": 385,
      "source_file": "content.md",
      "line_range": [432, 470],
      "content": "Let me walk through the Lagrangian derivation for a 2-link planar arm. This builds intuition for the structure before tackling 6-DOF systems.\n\nFor simplicity, assume point masses at the centers of mass and neglect link lengths beyond where mass is concentrated.\n\nKinetic energy of link 1:\nT_1 = 1/2 * m_1 * (L_c1 * dot{q}_1)^2\n\nKinetic energy of link 2:\nLink 2's velocity has two components: rotation about joint 1 and rotation about joint 2.\nT_2 = 1/2 * m_2 * [(L_1 * dot{q}_1)^2 + (L_c2 * (dot{q}_1 + dot{q}_2))^2 + 2 * L_1 * L_c2 * dot{q}_1 * (dot{q}_1 + dot{q}_2) * cos(q_2)]\n\nTotal kinetic energy:\nCombining and collecting terms by dot{q}^T M(q) dot{q}:\nT = 1/2 * dot{q}^T * [[m_1 * L_c1^2 + m_2*(L_1^2 + L_c2^2 + 2*L_1*L_c2*cos(q_2)), m_2*(L_c2^2 + L_1*L_c2*cos(q_2))], [m_2*(L_c2^2 + L_1*L_c2*cos(q_2)), m_2*L_c2^2]] * dot{q}\n\nPotential energy:\nV = -m_1 * g * L_c1 * cos(q_1) - m_2 * g * (L_1 * cos(q_1) + L_c2 * cos(q_1 + q_2))\n\nLagrangian: L = T - V\n\nApplying Euler-Lagrange for q1:\nAfter substantial algebra (which we would do symbolically in practice), we get:\n(m_1*L_c1^2 + m_2*L_1^2 + m_2*L_c2^2 + 2*m_2*L_1*L_c2*cos(q_2)) * q_ddot_1 + (m_2*L_c2^2 + m_2*L_1*L_c2*cos(q_2)) * q_ddot_2 - 2*m_2*L_1*L_c2*sin(q_2)*dot{q}_1*dot{q}_2 - m_2*L_1*L_c2*sin(q_2)*dot{q}_2^2 + (m_1*L_c1 + m_2*L_1)*g*sin(q_1) + m_2*g*L_c2*sin(q_1 + q_2) = tau_1\n\nThis looks complex, but the pattern is clear: each term belongs to M(q), C(q, dot{q}), or g(q). The symbolic derivation clarifies the structure; numerical implementation just evaluates the matrices."
    },
    {
      "chunk_id": "ch2_theory_011",
      "chapter": 2,
      "section": "2.5",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "theory",
      "title": "Newton-Euler Formulation for Efficient Dynamics",
      "keywords": ["Newton_Euler", "recursive_algorithm", "forward_backward_passes", "O_n_complexity", "inverse_dynamics"],
      "learning_objectives": ["LO2.4"],
      "tokens": 285,
      "source_file": "content.md",
      "line_range": [491, 530],
      "content": "The Lagrangian approach is elegant and provides deep insight into robot dynamics. However, it is computationally expensive—computing the mass matrix requires O(n^3) operations for an n-joint arm. For real-time control at 500 Hz on the Unitree G1, we need something faster.\n\nThe Newton-Euler formulation computes dynamics in linear time O(n) using two passes through the kinematic chain:\n\nForward pass: Compute angular velocities, angular accelerations, and linear accelerations for each link, propagating from base to end-effector.\n\nBackward pass: Compute forces and torques at each joint, propagating from end-effector back to the base.\n\nFor each link i, the forward pass computes:\nomega_i = R_{i-1}^i * omega_{i-1} + dot{q}_i * z_{i-1}\nalpha_i = R_{i-1}^i * alpha_{i-1} + q_ddot_i * z_{i-1} + omega_{i-1} x dot{q}_i * z_{i-1}\na_i = R_{i-1}^i * a_{i-1} + alpha_i x p_i^{i-1} + omega_i x (omega_i x p_i^{i-1})\n\nThe backward pass computes forces and torques:\nf_i = R_i^{i+1} * f_{i+1} + m_i * (a_i + g)\nn_i = R_i^{i+1} * n_{i+1} + p_com^i x f_i + I_i * alpha_i + omega_i x (I_i * omega_i)\n\nThe joint torque is the projection of n_i onto the joint axis.\n\nUse the Lagrangian approach when: deriving symbolic equations for analysis, teaching dynamics fundamentals, computing the mass matrix explicitly, or the robot has few degrees of freedom.\n\nUse Newton-Euler when: implementing real-time control at high frequency, computing inverse dynamics (torques from motions), the robot has many degrees of freedom, or memory and computation are constrained."
    },
    {
      "chunk_id": "ch2_theory_012",
      "chapter": 2,
      "section": "2.6",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Physics Engines for Robot Simulation",
      "keywords": ["physics_engines", "MuJoCo", "Gazebo", "PyBullet", "simulation"],
      "learning_objectives": ["LO2.5"],
      "tokens": 225,
      "source_file": "content.md",
      "line_range": [556, 580],
      "content": "Theory guides us, but robots exist in the physical world. Before deploying control algorithms on the Unitree G1, we validate them in simulation. This section covers the physics engines that power robot simulation and the practical considerations for meaningful results.\n\nThree engines dominate robotics simulation:\n\nMuJoCo (Multi-Joint Dynamics with Contact) uses optimization-based contact dynamics with a convex formulation. It is the gold standard for manipulation and contact-rich tasks. The native format is MJCF (XML), though URDF import is supported.\n\nGazebo Harmonic (the latest ROS-integrated version) provides a complete simulation environment with sensor models, plugin systems, and tight ROS 2 integration. The native format is SDF (Simulation Description Format), and it can use multiple physics backends.\n\nPyBullet offers a Python-native interface to the Bullet physics engine. It is popular for machine learning research because of its simplicity and easy installation via pip."
    },
    {
      "chunk_id": "ch2_code_004",
      "chapter": 2,
      "section": "2.6",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "code",
      "title": "MuJoCo Simulation of Robot Arm Dynamics",
      "keywords": ["MuJoCo", "XML_model", "simulation_step", "dynamics_simulation", "python"],
      "learning_objectives": ["LO2.5"],
      "tokens": 285,
      "source_file": "content.md",
      "line_range": [604, 640],
      "content": "The Unitree G1's dynamics can be simulated in MuJoCo by defining an MJCF model:\n\nimport mujoco\nimport numpy as np\n\n# Load the model\nmodel = mujoco.MjModel.from_xml_path('unitree_g1_arm.xml')\ndata = mujoco.MjData(model)\n\n# Run a simulation step\ndef simulate_step(tau):\n    '''Apply torques and step simulation.'''\n    data.ctrl[:] = tau  # Set joint torques\n    mujoco.mj_step(model, data)  # Advance physics\n    return data.qpos.copy(), data.qvel.copy()  # Return state\n\n# Simulate gravity-only dynamics\nprint('Simulating passive dynamics under gravity...')\nfor _ in range(1000):\n    # Zero torque - let gravity act\n    q, qd = simulate_step(np.zeros(6))\n\nprint(f'Final joint positions: {np.degrees(q)} degrees')\nprint(f'Final joint velocities: {qd} rad/s')"
    },
    {
      "chunk_id": "ch2_theory_013",
      "chapter": 2,
      "section": "2.6",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Integration Methods and Simulation Stability",
      "keywords": ["integration_methods", "RK4", "implicit_integration", "timestep", "numerical_stability"],
      "learning_objectives": ["LO2.5"],
      "tokens": 195,
      "source_file": "content.md",
      "line_range": [631, 655],
      "content": "Physics engines solve differential equations numerically. The integration method determines accuracy and stability:\n\nEuler integration (explicit) is first-order accurate but unstable for stiff systems. It is rarely used for robot dynamics.\n\nRK4 (Runge-Kutta 4th order) offers a good balance of accuracy and stability for most robotics applications.\n\nImplicit integration solves for acceleration given forces, providing unconditional stability at the cost of more computation per timestep. MuJoCo uses implicit integration by default.\n\nFor the Unitree G1 running at 500 Hz control frequency, MuJoCo's default 1ms timestep with implicit integration provides stable, accurate dynamics.\n\nThe sim-to-real gap is real. Contact dynamics in simulation differ significantly from reality due to friction model approximations, contact point computation, and deformation. A controller that tracks perfectly in simulation may fail on hardware. Validate with domain randomization: vary friction, damping, and mass parameters in simulation and test across the range on hardware."
    },
    {
      "chunk_id": "ch2_theory_014",
      "chapter": 2,
      "section": "2.6",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "theory",
      "title": "Simulation Validation and Sim-to-Real Gap",
      "keywords": ["simulation_validation", "analytical_comparison", "sim_to_real", "domain_randomization", "model_parameters"],
      "learning_objectives": ["LO2.5"],
      "tokens": 275,
      "source_file": "content.md",
      "line_range": [645, 690],
      "content": "A crucial verification step compares simulation output against analytical dynamics computed via Lagrangian methods. If simulation and theory disagree, there is a modeling error somewhere.\n\nA validation function would: set initial configuration, apply zero torque (passive dynamics), compare simulated acceleration with M(q)^(-1) * (-C(q, qd) - g(q)).\n\nBest practices for robot simulation:\n\n1. Verify model parameters: Masses, inertias, and centers of mass must match the physical robot. CAD models provide good approximations but may need calibration.\n\n2. Check units: MuJoCo uses SI units (meters, kilograms, seconds). Mixing units (centimeters instead of meters) causes physically unrealistic motion.\n\n3. Tune contact parameters: Friction coefficients, contact shapes, and solver iterations significantly affect contact behavior. Calibrate against real surfaces.\n\n4. Use deterministic seeding: For reproducible results, set random seeds for both physics and rendering.\n\n5. Profile computation time: Ensure simulation runs faster than real-time for training applications, or matches real-time for hardware-in-the-loop testing."
    },
    {
      "chunk_id": "ch2_lab_001",
      "chapter": 2,
      "section": "lab",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "lab",
      "title": "Lab 2.1: Forward Kinematics Implementation",
      "keywords": ["forward_kinematics_lab", "DH_table", "visualization", "2DOF_arm", "matplotlib"],
      "learning_objectives": ["LO2.2"],
      "tokens": 95,
      "source_file": "content.md",
      "line_range": [728, 730],
      "content": "Lab 2.1 (30 min): Implement forward kinematics for a 2-DOF planar arm. Define the DH table, compute the end-effector position for various joint configurations, and visualize the arm in matplotlib."
    },
    {
      "chunk_id": "ch2_lab_002",
      "chapter": 2,
      "section": "lab",
      "subsection": null,
      "difficulty": "intermediate",
      "content_type": "lab",
      "title": "Lab 2.2: Inverse Kinematics Implementation",
      "keywords": ["inverse_kinematics_lab", "analytical_IK", "numerical_IK", "DLS", "3DOF_arm"],
      "learning_objectives": ["LO2.3"],
      "tokens": 95,
      "source_file": "content.md",
      "line_range": [730, 732],
      "content": "Lab 2.2 (45 min): Implement analytical inverse kinematics for a 2-DOF arm, handling both elbow-up and elbow-down solutions. Then implement numerical IK for a 3-DOF arm using damped least squares."
    },
    {
      "chunk_id": "ch2_lab_003",
      "chapter": 2,
      "section": "lab",
      "subsection": null,
      "difficulty": "advanced",
      "content_type": "lab",
      "title": "Lab 2.3: Lagrangian Dynamics and MuJoCo Validation",
      "keywords": ["Lagrangian_lab", "MuJoCo_validation", "analytical_dynamics", "acceleration_comparison"],
      "learning_objectives": ["LO2.4", "LO2.5"],
      "tokens": 95,
      "source_file": "content.md",
      "line_range": [732, 734],
      "content": "Lab 2.3 (60 min): Create a MuJoCo simulation of a 2-link arm. Derive Lagrangian dynamics equations analytically, then compare simulated accelerations against analytical predictions to validate your model."
    }
  ]
}
